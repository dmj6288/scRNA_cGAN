{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fd1d7d-3881-4d2d-81c6-8502b672dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc07f1b58aa5446a99f1f3c9c4187a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/9.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72381dd7b74d49eb8ed8ec3673673ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/3.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e8ebeaa8a2499395067a867a470df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/179M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Use the correct tokenizer and model for ChemBERTa\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "model = RobertaModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3a5aa3-1d41-4aa3-a69c-0a85e1a89d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.812642  0.407679 -0.034935  0.192313 -0.297040 -0.310102 -0.575852   \n",
      "1  0.537932  0.146034 -0.158660 -0.712971 -0.038075 -1.054943 -0.403816   \n",
      "2 -0.724743 -0.385784 -0.228628 -0.961522  0.649793 -1.763603  0.086294   \n",
      "\n",
      "        7         8         9    ...       758       759       760       761  \\\n",
      "0 -0.571581  0.265512 -0.649386  ...  0.773662 -0.504897  0.132977 -0.518708   \n",
      "1  0.120810 -1.168498  0.707663  ...  1.150743 -0.552200  0.131314 -0.764380   \n",
      "2 -0.333877 -0.561120  0.118316  ...  0.226266 -0.501020 -0.537967 -1.169865   \n",
      "\n",
      "        762       763       764       765       766       767  \n",
      "0 -0.693730  2.000358  0.187271 -0.262813 -0.602395  1.409950  \n",
      "1  0.983986  0.256525 -0.830974 -1.576819 -0.002441  2.146913  \n",
      "2  0.673772  1.377905 -0.614138 -0.868043  0.607155  2.236074  \n",
      "\n",
      "[3 rows x 768 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example SMILES strings\n",
    "smiles_data = [\n",
    "    \"O=C1C=C(C(NCC2=CC3=C(C=C(CNCC4CCC4)N3)C=C2)=O)N=C5C=CC=CN15\",\n",
    "    \"CC(=O)OC1=CC=CC=C1C(=O)O\",\n",
    "    \"CC1=CC(=O)C=CC1=O\"\n",
    "]\n",
    "\n",
    "# Function to get embeddings for a batch of SMILES\n",
    "def get_chemberta_embeddings(smiles_list):\n",
    "    embeddings = []\n",
    "    for smiles in smiles_list:\n",
    "        # Tokenize the SMILES string\n",
    "        inputs = tokenizer(smiles, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        # Get embeddings from the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Extract the [CLS] token embedding (typically used as a summary representation)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embedding.squeeze().numpy())\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Get embeddings for the SMILES data\n",
    "embeddings = get_chemberta_embeddings(smiles_data)\n",
    "\n",
    "# Convert to a DataFrame for visualization or further processing\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "print(embeddings_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
